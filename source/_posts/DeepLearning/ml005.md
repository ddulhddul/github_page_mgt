---
title: Jupyter Test
date: 2018-01-28 19:23:52
categories:
  - DeepLearning
tags:
  - DeepLearning
  - 밑바닥부터 시작하는 딥러닝
---

```python python
from keras.utils import np_utils
from keras.datasets import mnist
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten
from keras.optimizers import SGD, Adagrad, RMSprop, Adam
from keras.regularizers import l2
import keras
import numpy as np

np.random.seed(3)

# 훈련셋과 시험셋 로딩
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()

# 훈련셋과 검증셋 분리
X_val = X_train[50000:]
Y_val = Y_train[50000:]
X_train = X_train[:50000]
Y_train = Y_train[:50000]

## 나누기 연산이 들어가므로 uint8 -> float32로 변경
## preprocessing (feature scaling)
X_train = X_train.reshape(50000, 784).astype('float32') / 255.0
X_val = X_val.reshape(10000, 784).astype('float32') / 255.0
X_test = X_test.reshape(10000, 784).astype('float32') / 255.0

X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') 
X_val = X_val.reshape(X_val.shape[0], 28, 28, 1).astype('float32') 
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') 



# 훈련셋, 검증셋 고르기
train_rand_idxs = np.random.choice(50000, 700)
val_rand_idxs = np.random.choice(10000, 300)

X_train = X_train[train_rand_idxs]
Y_train = Y_train[train_rand_idxs]
X_val = X_val[val_rand_idxs]
Y_val = Y_val[val_rand_idxs]

# 라벨링 전환
# convert class vectors 
# Lable의 categorical 값을 One-hot 형태로 변환 
# 예를 들어 [1, 3, 2, 0] 를 
# [[ 0., 1., 0., 0.], 
# [ 0., 0., 0., 1.], 
# [ 0., 0., 1., 0.], 
# [ 1., 0., 0., 0.]] 
# 로 변환하는 것을 One-hot 형태라고 함
Y_train = np_utils.to_categorical(Y_train)
Y_val = np_utils.to_categorical(Y_val)
Y_test = np_utils.to_categorical(Y_test)

# 2. 모델 구성하기
# 2.1) sequential 모델
# 
model = Sequential()
model.add(Conv2D(6, kernel_size=(3, 3), activation='relu',input_shape=(28, 28, 1), padding='same', strides=(1, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Conv2D(6, kernel_size=(3, 3), activation='relu', padding='same', strides=(1, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(84, activation='relu'))
model.add(Dense(10, activation='softmax'))



# 3. 모델 엮기
modified_optimizer = Adam(lr=0.005)
model.compile(loss='categorical_crossentropy', optimizer=modified_optimizer, metrics=['accuracy'])
# model.compile(loss='mean_squared_error', optimizer=modified_optimizer, metrics=['accuracy'])

# 4. 모델 학습시키기
tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)
model.fit(X_train, Y_train, epochs=20, batch_size=10, validation_data=(X_val, Y_val), callbacks=[tb_hist])
```