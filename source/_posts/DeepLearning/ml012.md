---
title: 케라스맛 Chapter4] 케라스로 구현하는 CNN (합성곱신경망)
date: 2018-04-15 20:00:52
categories:
  - DeepLearning
tags:
  - DeepLearning
  - 코딩셰프의 3분 딥러닝, 케라스맛
---


> 영상처리에 많이 활용되는 합성곱을 이용하는 인공신경망 기술.

# 4.1 CNN 원리
- 합성곱 필터를 이용해 신경망 동작을 수행.
    - 합성곱계층 : 특징점을 효과적으로 찾는데 활용.
    - 완전연결계층 : 찾으나 특징점을 기반으로 이미지를 분류하는데 주로 활용.
    > 주 목적은 그렇지만... 스스로 학습해 신경망이 최적화되기 때문에 그역할이 적정하게 둘에 분배된다. 한쪽이 절대적으로 특정 역할을 하는게 아니다.

- CNN과 DNN 비교
    - DNN은 이미지를 1차원 벡터로 변환하여 처리하기 때문에 2차원 특성을 처리하기엔 한계가 있다.
    - 반면 CNN은 2차원 이상의 데이터 처리에 적합하다. 
    - CNN 은 이미지의 높이와 넓이를 생각하며 2차원 처리를 수행.

- CNN 은 합성곱 계층이 끝나면 맥스풀링 계층을 이용해 각 지역별로 최댓값을 찾아줘서 특징점 위치가 약간씩 달라져도 딥러닝을 제대로 수행한다.

# 4.2 필기체를 분류하는 CNN 구현
  - 4.2.1 분류 CNN 모델링
  - 4.2.2 분류 CNN을 위한 데이터 준비  
  - 4.2.3 학습 효과 분석
  - 4.2.3 분류 CNN 학습 및 테스트

## 4.2.1 분류 CNN 모델링
```python
###############################
# 분류 CNN 모델링
###############################
import keras
from keras import models, layers
from keras import backend # 딥러닝 엔진들 함수를 직접 호출하거나 주요 파라미터 제어

class CNN(models.Sequential):
    def __init__(self, input_shape, num_classes):
        super().__init__()

        # 1. 3X3 커널 32개로 구성된 합성곱 계층
        self.add(layers.Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
        
        # 2. 64커널수, Maxpooling 이 부속계층으로 있음. (가중치가 바뀌진 않지만 특정한 형태로 변화시키는 계층을 부속계층이라고 한다고 합니다)
        self.add(layers.Conv2D(64, (3, 3), activation='relu'))
        self.add(layers.MaxPooling2D(pool_size=(2, 2)))
        self.add(layers.Dropout(0.25))
        
        # 3. 완전연결계층. Flatten : 2차원 이미지를 1차원으로 변화시킴
        self.add(layers.Flatten())
        self.add(layers.Dense(128, activation='relu'))
        self.add(layers.Dropout(0.5))
        self.add(layers.Dense(num_classes, activation='softmax'))

        # 4. 컴파일
        self.compile(loss=keras.losses.categorical_crossentropy,
                      optimizer='rmsprop',
                      metrics=['accuracy'])
```

## 4.2.2 분류 CNN을 위한 데이터 준비  
```python
###############################
# 분류 CNN을 위한 데이터 준비  
###############################
from keras import datasets 

class DATA():
    def __init__(self):
        num_classes = 10

        (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()
        img_rows, img_cols = x_train.shape[1:]

        # 흑백 이미지는 채널 정보가 존재하지 않아서, 추가적인 차원을 이미지 데이터에 포함하는 작업.
        if backend.image_data_format() == 'channels_first':
            # 샘플수, 채널수, 이미지 가로길이, 이미지세로길이
            x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
            x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
            input_shape = (1, img_rows, img_cols)
        else:
            # 샘플수, 이미지 가로길이, 이미지세로길이, 채널수
            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
            input_shape = (img_rows, img_cols, 1)

        x_train = x_train.astype('float32')
        x_test = x_test.astype('float32')
        x_train /= 255
        x_test /= 255

        y_train = keras.utils.to_categorical(y_train, num_classes)
        y_test = keras.utils.to_categorical(y_test, num_classes)
        
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.x_train, self.y_train = x_train, y_train
        self.x_test, self.y_test = x_test, y_test

```

## 4.2.3 학습 효과 분석
```python
###########################
# 학습 효과 분석
###########################
from keraspp.skeras import plot_loss, plot_acc
import matplotlib.pyplot as plt

```

## 4.2.3 분류 CNN 학습 및 테스트
```python
###############################
# 분류 CNN 학습 및 테스트
###############################
def main():
    # 1회 학습시 입력 데이터를 128개씩 나눠서 입력.
    batch_size = 128
    epochs = 10

    data = DATA()
    model = CNN(data.input_shape, data.num_classes)

    history = model.fit(data.x_train, data.y_train,
              batch_size=batch_size,
              epochs=epochs,
              # 검증용 데이터는 학습데이터의 일부를 사용
              validation_split=0.2)

    score = model.evaluate(data.x_test, data.y_test)
    print()
    print('Test loss:', score[0])
    print('Test accuracy:', score[1])

    plot_loss(history)
    plt.show()
    plot_acc(history)
    plt.show()

if __name__ == '__main__':
    main()
```
## http://localhost:8888/notebooks/nb_ex4_1_cnn_mnist_cl.ipynb

# 4.3 컬러 이미지를 분류하는 CNN 구현
- 필기체 분류와 크게 다르지 않다.
- CIFAR-10
  - 4.3.1 분류 CNN 패키지 임포트
  - 4.3.2 분류 CNN 모델링
  - 4.3.3 분류 CNN을 위한 데이터 준비
  - 4.3.4 분류 CNN의 학습 및 성능 평가를 위한 머신 클래스 구현
  - 4.3.5 분류 CNN의 학습 및 성능 평가 수행

## 4.3.1 분류 CNN 패키지 임포트

```python
from sklearn import model_selection, metrics
# 지정한 최대 최소값을 이용해 입력값 크기 조정
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import matplotlib.pyplot as plt
import os

# 케라스 모델링을 위한 서브패키지들
from keras import backend as K
from keras.utils import np_utils
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout

from . import skeras
from . import sfile
```

## 4.3.2 분류 CNN 모델링
- LeNet 신경망 모델 사용
    - 합성곱 계층 2개, 완전연결계층 1개
    - Conv2D(), Maxpoling2D() : 채널에 처리가 있는 계층
    - Dense() : 채널에 대한 처리가 없는 계층

```python
class CNN(Model):
    def __init__(model, nb_classes, in_shape=None):
        model.nb_classes = nb_classes
        model.in_shape = in_shape
        model.build_model()
        super().__init__(model.x, model.y)
        model.compile()

    def build_model(model):
        nb_classes = model.nb_classes
        in_shape = model.in_shape

        # 주어진 입력 이미지의 크기를 처리하는 입력 계층을 정의
        x = Input(in_shape)

        # 합성곱 계층 두 개를 정의
        h = Conv2D(32, kernel_size=(3, 3), activation='relu',
                   input_shape=in_shape)(x)
        h = Conv2D(64, (3, 3), activation='relu')(h)

        h = MaxPooling2D(pool_size=(2, 2))(h) # 가로세로 두 축으로 반반씩 줄어듬
        h = Dropout(0.25)(h)

        # 합성곱 계층을 완전연결 계층으롤 보내기 위해 플랫턴 작업
        # 3차원 데이터 -> 1차원
        h = Flatten()(h)
        z_cl = h

        # 완전연결계층의 은닉 계층과 출력 계층
        h = Dense(128, activation='relu')(h)
        h = Dropout(0.5)(h)
        z_fl = h
        y = Dense(nb_classes, activation='softmax', name='preds')(h)

        model.cl_part = Model(x, z_cl)
        model.fl_part = Model(x, z_fl)

        model.x, model.y = x, y

    def compile(model):
        Model.compile(model, loss='categorical_crossentropy',
                      optimizer='adadelta', metrics=['accuracy'])
```

## 4.3.3 분류 CNN을 위한 데이터 준비
```python
# 데이터를 머신러닝에 사용하기 적합하도록 조정하는 역할
class DataSet():
    def __init__(self, X, y, nb_classes, scaling=True, test_size=0.2, random_state=0):
        """
        X is originally vector. Hence, it will be transformed
        to 2D images with a channel (i.e, 3D).
        """
        self.X = X
        self.add_channels()

        X = self.X
        # the data, shuffled and split between train and test sets
        X_train, X_test, y_train, y_test = model_selection.train_test_split(
            X, y, test_size=0.2, random_state=random_state)

        print(X_train.shape, y_train.shape)

        X_train = X_train.astype('float32')
        X_test = X_test.astype('float32')

        if scaling:
            # scaling to have (0, 1) for each feature (each pixel)
            scaler = MinMaxScaler()
            n = X_train.shape[0]
            # 스케일링 기준은 X_train 으로만 해야한다. X_test는 X_train으로부터 정해진 기준을 따르게 한다.
            X_train = scaler.fit_transform(
                X_train.reshape(n, -1)).reshape(X_train.shape)
            n = X_test.shape[0]
            X_test = scaler.transform(
                X_test.reshape(n, -1)).reshape(X_test.shape)
            self.scaler = scaler

        print('X_train shape:', X_train.shape)
        print(X_train.shape[0], 'train samples')
        print(X_test.shape[0], 'test samples')

        # convert class vectors to binary class matrices
        Y_train = np_utils.to_categorical(y_train, nb_classes)
        Y_test = np_utils.to_categorical(y_test, nb_classes)

        self.X_train, self.X_test = X_train, X_test
        self.Y_train, self.Y_test = Y_train, Y_test
        self.y_train, self.y_test = y_train, y_test
        # self.input_shape = input_shape

    # 채널 정보를 데이터에 포함시키는 과정
    def add_channels(self):
        X = self.X

        # 흑백 이미지인지 검사
        if len(X.shape) == 3:
            N, img_rows, img_cols = X.shape

            if K.image_dim_ordering() == 'th':
                X = X.reshape(X.shape[0], 1, img_rows, img_cols)
                input_shape = (1, img_rows, img_cols)
            else:
                X = X.reshape(X.shape[0], img_rows, img_cols, 1)
                input_shape = (img_rows, img_cols, 1)
        else:
            input_shape = X.shape[1:]  # channel is already included.

        self.X = X
        self.input_shape = input_shape
```

## 4.3.4 분류 CNN의 학습 및 성능 평가를 위한 머신 클래스 구현

```python
# 학습 및 성능 평가 코드가 들어 있는 클래스
class Machine():
    def __init__(self, X, y, nb_classes=2, fig=True):
        self.nb_classes = nb_classes
        self.set_data(X, y)
        self.set_model()
        # 수행결과를 그림으로 보여줄지
        self.fig = fig

    def set_data(self, X, y):
        nb_classes = self.nb_classes
        self.data = DataSet(X, y, nb_classes)
        print('data.input_shape', self.data.input_shape)

    def set_model(self):
        nb_classes = self.nb_classes
        data = self.data
        self.model = CNN(nb_classes=nb_classes, in_shape=data.input_shape)
        # cnn_lenet(nb_classes=nb_classes, in_shape=data.input_shape)

    def fit(self, 
            epochs=10,      # 에포크
            batch_size=128, # 학습시 한번에 처리할 블록 길이
            verbose=1       # 화면에 진행사항 표시방법
        ):
        data = self.data
        model = self.model

        # 학습 시작
        history = model.fit(data.X_train, data.Y_train, batch_size=batch_size, epochs=epochs,
                            verbose=verbose, validation_data=(data.X_test, data.Y_test))
        return history

    # 학습과 성능 평가 전체를 진행
    def run(self, epochs=10, batch_size=128, verbose=1):
        data = self.data
        model = self.model
        fig = self.fig

        history = self.fit(epochs=epochs,
                           batch_size=batch_size, verbose=verbose)

        score = model.evaluate(data.X_test, data.Y_test, verbose=0)

        print('Confusion matrix')
        Y_test_pred = model.predict(data.X_test, verbose=0)
        y_test_pred = np.argmax(Y_test_pred, axis=1)
        print(metrics.confusion_matrix(data.y_test, y_test_pred))

        print('Test score:', score[0])
        print('Test accuracy:', score[1])

        # Save results
        suffix = sfile.unique_filename('datatime')
        foldname = 'output_' + suffix
        os.makedirs(foldname)
        skeras.save_history_history(
            'history_history.npy', history.history, fold=foldname)
        model.save_weights(os.path.join(foldname, 'dl_model.h5'))
        print('Output results are saved in', foldname)

        # 학습 곡선 그리기
        if fig:
            plt.figure(figsize=(12, 4))
            plt.subplot(1, 2, 1)
            skeras.plot_acc(history)
            plt.subplot(1, 2, 2)
            skeras.plot_loss(history)
            plt.show()

        self.history = history

        return foldname

```

## 4.3.5 분류 CNN의 학습 및 성능 평가 수행

## http://localhost:8888/notebooks/nb_ex4_2_cnn_cifar10_cl.ipynb

# 4.4 마치며
- CNN 은 합성곱 계층을 이용해 적은 가중치 수로도 이미지 분류에서 높은 성능(?)을 낸다.
- 가중치 수가 적기 때문에 과적합의 가능성도 낮아진다.
- 이미지 특성에 맞게 합성곱 필터링이 이루어지기 때문에 이미지 내에 있는 특징점을 잘 찾아낸다.
