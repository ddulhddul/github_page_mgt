---
title: Chapter8. 딥러닝
date: 2018-03-02 15:23:52
categories:
  - DeepLearning
tags:
  - DeepLearning
  - 밑바닥부터 시작하는 딥러닝
---

![밑바닥부터 시작하는 딥러닝](/images/deeplearning/cover.jpg)

https://www.slideshare.net/sunggonSong/8-75266382

https://books.google.co.kr/books?id=SM9KDwAAQBAJ&pg=PA269&dq=ILSVRC+%EC%B5%9C%EC%9A%B0%EC%88%98+%ED%8C%80+%EC%84%B1%EC%A0%81+%EC%B6%94%EC%9D%B4&hl=ko&sa=X&ved=0ahUKEwigpu6Qn9LZAhWIu7wKHZDOCygQ6AEIJjAA#v=onepage&q=ILSVRC%20%EC%B5%9C%EC%9A%B0%EC%88%98%20%ED%8C%80%20%EC%84%B1%EC%A0%81%20%EC%B6%94%EC%9D%B4&f=false


딥러닝의 특징과 사례, 그리고 가능성

# 8.1 더 깊게
그동안 배운 기술을 집약하고 (CNN과 매개변수 최적화) 신경망을 만들어 MNIST 데이터셋 손글씨 숫자 인식에 도전하자

## 8.1.1 더 깊은 신경망으로
![손글씨 숫자를 인식하는 심층 CNN](/images/deeplearning/ml009/ml009_01.png)
- 이 신경망의 특징
  - 3X3 의 작은 필터를 사용한 합성곱 계층
  - 활성화 함수는 ReLU
  - 완전연결 계층 뒤에 드롭아웃 계층 사용
  - Adam을 사용해 최적화
  - 가중치 초깃값은 'He의 초깃값'

=> 잘못 인식할 확률이 겨우 0.62% 인 신경망이 탄생

![인식하지 못한 이미지들](/images/deeplearning/ml009/ml009_04.png)
=> 사람도 헷갈릴만한 이미지들이다.

## 8.1.2 정확도를 더 높이려면
- What is the class of this image ?
[http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)
{% iframe http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html %}

  - 책에 나온 기법의 정확도 순위(2016년 12월 기점)와 달라진게 없다.
  - 상위권은 대부분 CNN을 기초로한 기법들
  - 이 목록의 기법들의 CNN은 그다지 깊지 않다. (합성곱 계층 2개, 완전연결 계층 2개 정도인 신경망)
    - 손글씨 숫자라는 문제가 비교적 단순해서 라고 추측

### 데이터 확장
입력 이미지(훈련 이미지)를 알고리즘으로 인위적으로 확장.
![데이터 확장의 예](/images/deeplearning/ml009/ml009_05.png)
- 이미지 일부를 잘라내는 **crop**
- 좌우를 뒤집는 **flip** 등이 있다.
- 쉬운 트릭이라 생각하지만, 멋진 결과를 가져오는 경우가 많다.
- 한번 도전해봐도 좋을듯... ? (찾아보자)

## 8.1.3 깊게 하는 이유
1. ILSVRC 로 대표되는 이미지 인식 대회의 결과에서 파악할 수 있다.
  (찾아보자)
  - 딥러닝 기반이며, 층의 깊이에 비례해 정확도가 좋아지는 추세

2. 신경망의 매개변수 수가 줄어든다.
  - 깊게한 매개변수가 깊지 않은 경우보다 적은 매개변수로 같은 수준의 표현력을 달성할 수 있다.
  ![3X3의 합성곱 계층을 2회 반복한 예](/images/deeplearning/ml009/ml009_06.png)
  - 작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은, 매개변수 수를 줄여 넓은 **수용 영역**을 소화할 수 있다는 데에 있다.
  - 게다가 층을 거듭하면서, ReLU등의 활성화 함수를 합성곱 계층 사이에 끼움으로써, 신경망의 표현력이 개선된다.
    - 활성화 함수가 신경망에 **비선형** 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문.

3. 학습의 효율성
  - 층을 깊게 함으로써, 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다.
  - 7.6 CNN의 합성곱 계층이 정보를 계층적으로 추출하고 있음을 빌어 보면
  ![층 깊이에 따른 정보](/images/deeplearning/ml009/ml009_02.png)
    - 에지 등의 단순한 패턴에서 층이 깊어질수록 사물의 일부와 같은 점차 복잡한 것에 반응한다.
  - ex) 얕은 신경망에서 개를 인식하려면, 합성곱 계층을 개의 특징 대부분을 한번에 이해하여야한다. 하지만 신경망을 깊게하면 학습해야 할 문제를 계층적으로 분해할 수 있다.
  - 층을 깊게하면 정보를 계층적으로 전달 할 수 있다.
    - 에지를 추출한 정보를 다음 층에서 쓰고, 더 고도의 패턴을 효과적으로 학습하는것을 기대할 수 있다.

# 8.2 딥러닝의 초기 역사
딥러닝이 큰 주목을 받게 된 계기 - ImageNet Large Scale Visual Recognition Competition (ILSVRC)

## 8.2.1 이미지넷
- 100만장이 넘는 이미지를 담고 있는 데이터셋.
- 매년 열리는 ILSVRC는 이 거대 데이터셋을 사용해 자웅을 겨룬다.
![https://addingtonword.files.wordpress.com/2015/12/20151216-ilsvrc-image.jpg](https://addingtonword.files.wordpress.com/2015/12/20151216-ilsvrc-image.jpg)
- 몇가지 종목중 하나가 분류. 1000개의 클래스를 제대로 분류하는지 겨룸.
  ![ILSVRC 최우수 팀의 성적 추이](/images/deeplearning/ml009/ml009_03.png)
  - 2012년 이후 선두는 항상 딥러닝 방식이었다.
  - 2012 년 AlexNet이 오류율을 크게 낮췄고...
  - 2015년에는 150층이 넘는 심층 신경망인 ResNet이 오류율을 3.5% 까지 낮춤 (인간의 인식 능력을 넘어섰다 ?)
- 유명한 세 신경망에 대한 소개 (VGG, GoogLeNet, ResNet)
![CNN Architectures](/images/deeplearning/ml009/ml009_07.png)
  출처 : [https://www.slideshare.net/samchoi7/cnn-tutorial-66719728](https://www.slideshare.net/samchoi7/cnn-tutorial-66719728)

## 8.2.2 VGG
- A visualization of the VGG architecture
![A visualization of the VGG architecture](https://static.wixstatic.com/media/3c6d20_d485f152a74b4df8b3d4b0bf4484196e~mv2.png/v1/fill/w_658,h_386,al_c,lg_1/3c6d20_d485f152a74b4df8b3d4b0bf4484196e~mv2.png)
  - 비중있는 층(합성곱, 완전연결계층) 을 모두 16 or 19 층으로 심화한게 특징.
  - 주목할 점은 3X3 의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 것.
  - 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복.
  - 마지막엔 완전연결 계층을 통과시켜 결과를 출력
 - 성능면에서 GoogLeNet 에 뒤지지만 구성이 간단하여 응용하기 좋다.

## 8.2.3 GoogLeNet
![GoogleNet](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/GoogleNet.png)
  출처 : [https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/googlenet.html](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/googlenet.html)
- GoogLeNet에는 가로방향의 폭이 있다. 인셉션 구조. 그 기반구조는 다음과 같다.
  ![GoogLeNet 인셉션 구조](https://norman3.github.io/papers/images/google_inception/f01.png)
    출처 : [https://norman3.github.io/papers/docs/google_inception.html](https://norman3.github.io/papers/docs/google_inception.html)
  - 크기가 다른 필터(와 풀링)를 여러개 적용하여 그 결과를 결합.
  - 인셉션 구조를 하나의 빌딩 블록(구성요소로 사용하는 것이 GoogLeNet의 특징)
  - GoogLeNet에서는 1X1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용.
    - 채널 쪽으로 크기를 줄이는 것으로, 매개변수 제거와 고속 처리에 기여

## 8.2.4 ResNet
- 마이크로소프트의 팀이 개발한 네트워크.
- 지금까지보다 층을 더 깊게 할 수 있는 특별한 장치가 있다.
- 딥러닝은 층을 깊게 하는 것이 성능 향상에 중요하다. 하지만 층이 지나치게 깊으면 학습이 잘 되지 않고, 성능이 오히려 떨어지는데, 이를 해결하기 위해 **스킵 연결**을 도입
  - 층의 깊이에 비례해 성능을 향상 시킬 수 있는 핵심 요소.
    ![스킵 연결](/images/deeplearning/ml009/ml009_08.png)
    - weight layer 는 합성곱 계층을 말함.
    - 두 합성곱 계층을 뛰어넘어 스킵 연결로 인해 **F(x)+x** 가 되는게 핵심.
    - 이는 역전파 때 스킵 연결이 신호 감쇠를 막아주기 때문에 학습이 효율적으로 가능하다.
    - 스킵 연결로 기울기가 작아지거나 지나치게 커질 걱정 없이 **앞 층의 의미 있는 기울기**가 전해지리라 기대할 수 있다.

- ResNet
  ![ResNet](https://2.bp.blogspot.com/-J7j0eUkNJ-w/WPU7iXKs6II/AAAAAAAAJt0/FMY6pOVMu34y2TziHnVPbadohKim1XpKACLcB/s640/resnet_vs_plainnet.png)
   출처 : [http://alimurreza.blogspot.kr/2017/04/deep-residual-network-resnet.html](http://alimurreza.blogspot.kr/2017/04/deep-residual-network-resnet.html)
  - 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 학습한다.
- 전이 학습?
  - 이미지넷이 제공하는 거대한 데이터셋으로 학습한 가중치 결과를 실제 제품에 활용하기도 함.
  - 미리 학습된 가중치를 초기 값으로 설정하고 새로운 데이터셋을 대상으로 재학습을 수행.

# 8.3 더 빠르게(딥러닝 고속화)
- CPU만으로는 처리하기 부족한 계산을 GPU를 활용해 고속으로 처리할 수 있다.
- 최근 프레임워크에선 학습을 복수의 GPU와 여러 기기로 분산 수행.

## 8.3.1 풀어야 할 숙제
- AlexNet 각 층의 시간 비율
  ![AlexNet 각 층의 시간 비율](/images/deeplearning/ml009/ml009_09.png)
  - 오랜 시간을 합성곱 계층에서 소요한다. (GPU 전체의 95%, CPU 전체의 89%)
  - 합성곱 계층을 결국 단일 곱셈 누산이다. 즉, 딥러닝 고속화는 단일 곱셈 누산을 어떻게 효율적으로 개선하느냐가 관건이다.

## 8.3.2 GPU를 활용한 고속화
- GPU는 병렬 수치 연산을 고속으로 처리할 수 있다.
  - ex) 합성곱 계층에서 행하는 im2col
  ![AlexNet 학습 시간 비교](https://static.wixstatic.com/media/5dad68_a7c45717c03c45638b91608b90db7e1f~mv2.png/v1/fill/w_945,h_588,al_c,usm_0.66_1.00_0.01/5dad68_a7c45717c03c45638b91608b90db7e1f~mv2.png)
  - CPU에서는 40여일이 걸리지만, GPU로는 6일까지 단축.
  - cuDNN 딥ㅁ러닝 최적화 라이브러리를 사용하면 더욱 빨라짐.

- GPU는 엔비디아와 AMD 두 회사가 제공. 대부분 딥러닝 프레임워큰느 엔비디아 GPU에서 혜택을 받을 수 있다. 
  - CUDA 라는 엔비디아의 GPU컴퓨팅용 통합 개발 환경을 사용.
  - cuDNN 은 CUDA 위에서 동작하는 라이브러리.

## 8.3.3 분산 학습
- 뛰어난 신경망을 위해 시험을 수없이 반복해야하고, 1회 학습에 걸리는 시간을 단축해야한다. // 딥러닝 학습의 수평확장이 필요
- 다수의 GPU와 컴퓨터를 이용한 분산 학습을 지원한 딥러닝 프레임워크들이 나타나고 있다.
  - 상위 10가지 딥러닝 프레임워크 (https://www.nextobe.com/single-post/2017/08/01/%EC%83%81%EC%9C%84-10%EA%B0%80%EC%A7%80-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC)
    
    {% iframe https://www.nextobe.com/single-post/2017/08/01/%EC%83%81%EC%9C%84-10%EA%B0%80%EC%A7%80-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC %}

- 텐서플로우 분산 학습 성능
  ![텐서플로우 분산 학습 성능](https://tensorflowkorea.files.wordpress.com/2016/04/image00.png?w=625)
  - 100개를 사용하니 하나일때보다 56배 빨라짐.
  - 하지만 어떻게 분산시키느냐도 어려운 문제.
    - 컴퓨터사이 통신과 동기화 등

## 8.3.4 연산 정밀도와 비트 줄이기
- 메모리 용량과 버스 대역폭 등이 병목이 될 수 있다.
- 따라서 네트워크로 주고 받는 데이터의 비트 수는 최소로 만드는것이 바람직.
- 딥러닝은 높은수치의 정확도를 요구하지 않으므로. 데이터를 퇴화시켜도 출력에 주는 영향이 적다.
- 컴퓨터는 32비트 단정밀도, 64비트 배정밀도 등의 포맷이 있지만, 딥러닝은 **16비트 반정밀도**만 사용해도 학습에 문제가 없다고 알려져 있다.
  - 엔비디아의 최신 GPU인 **파스칼 아키텍처**는 이 포맷을 지원.
- 딥러닝 고속화 하기 위해 비트 수를 줄이는 연구는 계속 주시해야 한다.
  - 참고
    - 2016-04-08 [엔비디아 파스칼 아키텍처…달라진 5가지 포인트](http://www.techholic.co.kr/news/articleView.html?idxno=51874)
    - 2017-05-11 [파스칼보다 5배 빠르다? NVIDIA 볼타(Volta) 아키텍처 발표](http://www.bodnara.co.kr/bbs/article.html?num=140148)

# 8.4 딥러닝의 활용
우리가 지금까지 본 손글씨 숫자 인식 외에도 온갖 문제에 적용할 수 있다.

## 8.4.1 사물 검출
- 이미지 속에 담긴 사물의 위치와 종류를 알아내는 기술.
- 사물 인식보다 어려운 문제다. 어딘가에 있을 사물의 위치를 잡아내야 하고 여러 사물이 존재할 수 있음.
- CNN 을 이용한 **R-CNN** 이 유명하다.

### 참고 [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://jamiekang.github.io/2017/05/28/faster-r-cnn/)
- R-CNN
  ![R-CNN의 처리 흐름](https://tensorflowkorea.files.wordpress.com/2017/06/0sdj6skdrqyzpo6oh.png?w=6254)
  - Regional Proposal + CNN
  - Regional proposal을 얻기 위해 selective search 사용
  - CNN을 사용한 첫 번째 object detection method
  - 각 proposal을 독립적으로 계산 (= 많은 계산 필요)
  - Bounding box regression으로 detection 정확도 향상
- Fater R-CNN
  ![Fater R-CNN의 처리 흐름](https://jamiekang.github.io/media/2017-05-27-faster-r-cnn-fast-r-cnn-concept.jpg)
  - 같은 image의 proposal들이 convolution layer를 공유
  - ROI Pooling 도입
  - 전체 network이 End-to-end로 한 번에 학습
  - R-CNN보다 빠르고 더 정확한 결과

## 8.4.2 분할
- 이미지를 픽셀 수준에서 분류하는 문제.
- 단위로 객체마다 채색된 지도 데이터를 사용해 학습.
- 분할의 가장 단순한 방법은 모든 픽셀 각각을 추론하는 방법이지만, 긴 시간이 걸리므로,(합성곱 연산에서 많은 영역을 쓸데없이 다시 계산) 낭비를 줄여주는 **FCN** 이 고안됨. 
![이미지 분할 딥러닝](https://cdn-images-1.medium.com/max/632/1*wRkj6lsQ5ckExB5BoYkrZg.png)
  - 합성곱 계층으로만 구성된 네트워크
  - 사물 인식에서 사용한 신경망의 완전연결 계층에서는 중간 데이터의 공간 볼륨을 1차원으로 변환하여 한줄로 늘어선 노드들이 처리했으나, FCN에서는 공간 볼륨을 유지한 채 마지막 출력까지 처리할 수 있다.
  - 마지막에 공간 크기를 확대하는 처리를 도입했따는 것도 특징임.
  - 완전 연결계층을 같은 기능을 하는 합성곱 계층으로 바꾼다 ??? (찾아보자)

## 8.4.3 사진 캡션 생성
- NIC 모델이 대표적이다.
  ![NIC 모델](http://cfile28.uf.tistory.com/image/2263994E5486AC6D0D8726)
  - 심층 CNN과 자연어를 다루는 순환 신경망으로 구성된다.
  - CNN으로 사진 특징을 추출하고, 특징을 RNN으로 넘긴다.
  - RNN은 특징을 바탕으로 순환적으로 텍스트를 생성.
    - RNN은 이전에 생성한 정보에 영향을 받는다.
    - RNN 은 과거의 정보를 기억하면서 동작한다.
- 이미지 캡션 생성 사례  
![이미지 캡션 생성 사례](https://image.slidesharecdn.com/20170629osiafinal-170712023316/95/deep-learning-47-638.jpg?cb=1499826964)

- 자연어와 같은 여러 종류의 정보를 조합하고 처리하는 것을 **멀티모달 처리**라고 하여 최근 주목받는 다는데 ... ? (찾아보자)

# 8.5 딥러닝의 미래
## 8.5.1 이미지 스타일(화풍) 변환
두 이미지를입력해서 새로운 그림을 생성하는 연구. 하나는 콘텐츠 이미지, 하나는 스타일 이미지
![이미지 스타일(화풍) 변환](http://sanghyukchun.github.io/images/post/92-1.jpg)
- 네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습한다. 이를 통해, 입력 이미지로 콘텐츠 이미지의 형태를 흉내낼 수 있다.

## 8.5.2 이미지 생성
앞의 예와 달리, 아무런 입력 이미지 없이 새로운 이미지를 그려내는 연구, 대량의 이미지를 사용하여 먼저 학습이 필요
- **DCGAN** (Deep Convolutional Generative Adversarial Network) 기법
  - Alec Radford의 DCGAN 논문 에서 가져온 사진
  ![https://cdn-images-1.medium.com/max/640/1*n63ADMch0NU4RxLDt04rHA.png](https://cdn-images-1.medium.com/max/640/1*n63ADMch0NU4RxLDt04rHA.png)
  - 기술의 핵심은, 생성자와 식별자로 불리는 2개의 신경망을 이용하는 것.
    - 생성자는 진짜와 똑같은 이미지를 생성하고 식별자는 그것이 진짜인지(생성한것인지 찍은것인지) 판별한다.
    - 둘의 능력을 부지런히 갈고닦게 하는것이 **GAN** (Generative Adversarial Network) 기술
    - 지금까지의 input 데이터돠 정답 레이블을 짝지은 **지도학습** 과는 달리, 스스로 학습하는 **자율학습** 문제이다.
      - Deep Belief Network
      - Deep Boltzmann Machine

## 8.5.3 자율 주행
- SegNet :  주변 환경을 인식하는 CNN 기반 신경망  
![http://mi.eng.cam.ac.uk/projects/segnet/images/CamVidTeaserwithIndoorScenes.jpg](http://mi.eng.cam.ac.uk/projects/segnet/images/CamVidTeaserwithIndoorScenes.jpg)

## 8.5.4 Deep Q-Network(강화학습)
- 에이전트라는 것이 환경에 맞게 행동을 선택하고, 행동에 의해서 환경이 변한다는게 기본적인 틀.
- 강화 학습의 목적은 에이전트의 행동 지침을 더 나은 보상을 받는 쪽으로 바로잡는 것.
- 강화 학습의 기본 틀
  ![강화 학습의 기본 틀](https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/action-perception.png)
  - 정해진 보상이 아니라, 예상 보상이다.
  - 명확한 지표로부터 역산해서 예상 보상을 정해야 한다.
- Deep Q-Network
  - Q 학습이라는 강화학습 알고리즘을 기초로 함.
  - [Q Learning][https://ko.wikipedia.org/wiki/Q_%EB%9F%AC%EB%8B%9D]
  {% iframe https://ko.wikipedia.org/wiki/Q_%EB%9F%AC%EB%8B%9D %}
  - 최적 행동 가치 함수로 최적인 행동을 정한다.
  - 이 함수를 딥러닝(CNN)으로 비슷하게 흉내 내어 사용하는 것이 DQN
  ![Deep Q-Network](http://cfile23.uf.tistory.com/image/275B523D589EE0131CA4B5)
  - 그동안의 비디오 게임 학습과 다르게, 게임의 상태를 추출하는 것이 아닌 비디오 게임의 영상만을 입력 데이터로하여 학습한다. 수많은 게임에서 사람보다 뛰어난 성적을 거두고 있다고 하는데 ... ?? (찾아보자)
- 알파고에도 딥러닝과 강화학습이 이용되었다. 이들 모두 구글이 인수한 딥마인드가 진행한 연구라고 한다.
  - [구글 딥마인드 - 나무위키](https://namu.wiki/w/%EA%B5%AC%EA%B8%80%20%EB%94%A5%EB%A7%88%EC%9D%B8%EB%93%9C)
  {% iframe https://namu.wiki/w/%EA%B5%AC%EA%B8%80%20%EB%94%A5%EB%A7%88%EC%9D%B8%EB%93%9C %}

# 이번 장에서 배운 것
- 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.
- 이미지 인식 기술 대회인 ILSVRC에서는 최근 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이도 더 깊어지는 추세다.
- 유명한 신경망으로는 VGG, GoogLeNet, ResNet이 있다.
- GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화할 수 있다.
- 딥러닝(신경망)은 사물 인식뿐 아니라 삼루검출과 분할에도 이용할 수 있다.
- 딥러닝의 응용 분야로는 사진의 갭션 생성, 이미지 생성, 강화학습 등이 있다. 쵝느에는 자율 주행에도 딥러닝을 접목하고 있어 기대된다.
